{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tz28/deep-learning/blob/master/compare_initializations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对比几种初始化方法\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#初始化为0\n",
    "def initialize_parameters_zeros(layers_dims):\n",
    "\t\"\"\"\n",
    "\tArguments:\n",
    "\tlayer_dims -- python array (list) containing the size of each layer.\n",
    "\tReturns:\n",
    "\tparameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "\t\t\t\t\tW1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "\t\t\t\t\tb1 -- bias vector of shape (layers_dims[1], 1)\n",
    "\t\t\t\t\t...\n",
    "\t\t\t\t\tWL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "\t\t\t\t\tbL -- bias vector of shape (layers_dims[L], 1)\n",
    "\t\"\"\"\n",
    "\tparameters = {}\n",
    "\tL = len(layers_dims)  # number of layers in the network\n",
    "\n",
    "\tfor l in range(1, L):\n",
    "\t\tparameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l - 1]))\n",
    "\t\tparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\treturn parameters\n",
    "\n",
    "#随机初始化\n",
    "def initialize_parameters_random(layers_dims):\n",
    "\t\"\"\"\n",
    "\tArguments:\n",
    "\tlayer_dims -- python array (list) containing the size of each layer.\n",
    "\tReturns:\n",
    "\tparameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "\t\t\t\t\tW1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "\t\t\t\t\tb1 -- bias vector of shape (layers_dims[1], 1)\n",
    "\t\t\t\t\t...\n",
    "\t\t\t\t\tWL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "\t\t\t\t\tbL -- bias vector of shape (layers_dims[L], 1)\n",
    "\t\"\"\"\n",
    "\tnp.random.seed(3)  # This seed makes sure your \"random\" numbers will be the as ours\n",
    "\tparameters = {}\n",
    "\tL = len(layers_dims)  # integer representing the number of layers\n",
    "\tfor l in range(1, L):\n",
    "\t\tparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1])*0.01\n",
    "\t\tparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\treturn parameters\n",
    "\n",
    "#xavier initialization\n",
    "def initialize_parameters_xavier(layers_dims):\n",
    "\t\"\"\"\n",
    "\tArguments:\n",
    "\tlayer_dims -- python array (list) containing the size of each layer.\n",
    "\tReturns:\n",
    "\tparameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "\t\t\t\t\tW1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "\t\t\t\t\tb1 -- bias vector of shape (layers_dims[1], 1)\n",
    "\t\t\t\t\t...\n",
    "\t\t\t\t\tWL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "\t\t\t\t\tbL -- bias vector of shape (layers_dims[L], 1)\n",
    "\t\"\"\"\n",
    "\tnp.random.seed(3)\n",
    "\tparameters = {}\n",
    "\tL = len(layers_dims)  # integer representing the number of layers\n",
    "\tfor l in range(1, L):\n",
    "\t\tparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(1 / layers_dims[l - 1])\n",
    "\t\tparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\treturn parameters\n",
    "\n",
    "#He initialization\n",
    "def initialize_parameters_he(layers_dims):\n",
    "\t\"\"\"\n",
    "\tArguments:\n",
    "\tlayer_dims -- python array (list) containing the size of each layer.\n",
    "\tReturns:\n",
    "\tparameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "\t\t\t\t\tW1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
    "\t\t\t\t\tb1 -- bias vector of shape (layers_dims[1], 1)\n",
    "\t\t\t\t\t...\n",
    "\t\t\t\t\tWL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
    "\t\t\t\t\tbL -- bias vector of shape (layers_dims[L], 1)\n",
    "\t\"\"\"\n",
    "\tnp.random.seed(3)\n",
    "\tparameters = {}\n",
    "\tL = len(layers_dims)  # integer representing the number of layers\n",
    "\n",
    "\tfor l in range(1, L):\n",
    "\t\tparameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(2 / layers_dims[l - 1])\n",
    "\t\tparameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\treturn parameters\n",
    "\n",
    "def relu(Z):\n",
    "\t\"\"\"\n",
    "\t:param Z: Output of the linear layer\n",
    "\t:return:\n",
    "\tA: output of activation\n",
    "\t\"\"\"\n",
    "\tA = np.maximum(0,Z)\n",
    "\treturn A\n",
    "\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "\t\"\"\"\n",
    "\t:param layer_dims: list,每一层单元的个数（维度）\n",
    "\t:return:dictionary,存储参数w1,w2,...,wL,b1,...,bL\n",
    "\t\"\"\"\n",
    "\tnp.random.seed(3)\n",
    "\tL = len(layer_dims)#the number of layers in the network\n",
    "\tparameters = {}\n",
    "\tfor l in range(1,L):\n",
    "\t\tparameters[\"W\" + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*np.sqrt(2 / layer_dims[l - 1])\n",
    "\t\tparameters[\"b\" + str(l)] = np.zeros((layer_dims[l],1))\n",
    "\treturn parameters\n",
    "\n",
    "def forward_propagation(initialization=\"he\"):\n",
    "\tdata = np.random.randn(1000, 100000)\n",
    "\tlayers_dims = [1000,800,500,300,200,100,10]\n",
    "\tnum_layers = len(layers_dims)\n",
    "\t# Initialize parameters dictionary.\n",
    "\tif initialization == \"zeros\":\n",
    "\t\tparameters = initialize_parameters_zeros(layers_dims)\n",
    "\telif initialization == \"random\":\n",
    "\t\tparameters = initialize_parameters_random(layers_dims)\n",
    "\telif initialization == \"xavier\":\n",
    "\t\tparameters = initialize_parameters_xavier(layers_dims)\n",
    "\telif initialization == \"he\":\n",
    "\t\tparameters = initialize_parameters_he(layers_dims)\n",
    "\tA = data\n",
    "\tfor l in range(1,num_layers):\n",
    "\t\tA_pre = A\n",
    "\t\tW = parameters[\"W\" + str(l)]\n",
    "\t\tb = parameters[\"b\" + str(l)]\n",
    "\t\tz = np.dot(W,A_pre) + b #计算z = wx + b\n",
    "\t\t# A = np.tanh(z) #relu activation function\n",
    "\t\tA = relu(z)\n",
    "\t\tplt.subplot(2,3,l)\n",
    "\t\tplt.hist(A.flatten(),facecolor='g')\n",
    "\t\tplt.xlim([-1,1])\n",
    "\t\tplt.yticks([])\n",
    "\tplt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tforward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:newtorch]",
   "language": "python",
   "name": "conda-env-newtorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
